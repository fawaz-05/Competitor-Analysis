{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPRZ/m1shwe6Djuai0JHIrJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fawaz-05/Competitor-Analysis/blob/main/analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing libraries\n",
        "import json\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import requests\n",
        "import streamlit as st\n",
        "from openai import AzureOpenAI\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from transformers import pipeline\n",
        "\n",
        "\n",
        "#Follow the steps in README.md file to get the API keys and Azure OpenAI credentials\n",
        "API_KEY = \"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\" #Groq API Key\n",
        "SLACK_WEBHOOK = \"https://hooks.slack.com/services/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\" #Slack webhook url\n",
        "\n",
        "#It will minimze the length of text to specified length\n",
        "def truncate_text(text, max_length=512):\n",
        "    return text[:max_length]\n",
        "#Loading the data from the csv file\n",
        "def load_competitor_data():\n",
        "    \"\"\"Load competitor data from a CSV file.\"\"\"\n",
        "    data = pd.read_csv(\"/content/price_data.csv\")\n",
        "    print(data.head())\n",
        "    return data\n",
        "#loading the data from csv file\n",
        "def load_reviews_data():\n",
        "    \"\"\"Load reviews data from a CSV file.\"\"\"\n",
        "    reviews = pd.read_csv(\"/content/review_data.csv\")\n",
        "    return reviews\n",
        "#apply sentiment analysis pipeline using specific model\n",
        "def analyze_sentiment(reviews):\n",
        "    \"\"\"Analyze customer sentiment for reviews.\"\"\"\n",
        "    sentiment_pipeline = pipeline(\n",
        "    \"sentiment-analysis\",\n",
        "    model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\",\n",
        "    revision=\"714eb0f\"\n",
        "    )\n",
        "    return sentiment_pipeline([str(review) for review in reviews])\n",
        "\n",
        "#Train the model using Random Forest Regressor\n",
        "def train_predictive_model(data):\n",
        "    \"\"\"Train a predictive model for competitor pricing strategy.\"\"\"\n",
        "    data[\"Discount\"] = data[\"Discount\"].str.replace(\"%\", \"\").astype(float)\n",
        "    data[\"MRP Price\"] = data[\"MRP Price\"].astype(int)\n",
        "    data[\"Predicted_Discount\"] = data[\"Discount\"] + (data[\"MRP Price\"] * 0.05).round(2)\n",
        "\n",
        "    X = data[[\"MRP Price\", \"Discount\"]]\n",
        "    y = data[\"Predicted_Discount\"]\n",
        "    print(X)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, train_size=0.8\n",
        "    )\n",
        "\n",
        "    model = RandomForestRegressor(random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#Fitting ARIMA model for forecasting it has 3 arguments ARIMA(p,d,q)  p models autoregressive part d ensures stationarity through differencing and q ensures moving average part\n",
        "def forecast_discounts_arima(data, future_days=5):\n",
        "    \"\"\"\n",
        "    Forecast future discounts using ARIMA.\n",
        "    :param data: DataFrame containing historical discount data (with a datetime index).\n",
        "    :param future_days: Number of days to forecast.\n",
        "    :return: DataFrame with historical and forecasted discounts.\n",
        "    \"\"\"\n",
        "\n",
        "    data = data.sort_index()\n",
        "    print(product_data.index)\n",
        "\n",
        "    data[\"Discount\"] = pd.to_numeric(data[\"Discount\"], errors=\"coerce\")\n",
        "    data = data.dropna(subset=[\"Discount\"])\n",
        "\n",
        "    discount_series = data[\"Discount\"]\n",
        "    if not isinstance(data.index, pd.DatetimeIndex):\n",
        "        try:\n",
        "            data.index = pd.to_datetime(data.index)\n",
        "        except Exception as e:\n",
        "            raise ValueError(\n",
        "                \"Index must be datetime or convertible to datetime.\"\n",
        "            ) from e\n",
        "    #ARIMA(p,d,q)\n",
        "    model = ARIMA(discount_series, order=(5, 1, 0))\n",
        "    model_fit = model.fit()\n",
        "\n",
        "    forecast = model_fit.forecast(steps=future_days)\n",
        "    future_dates = pd.date_range(\n",
        "        start=discount_series.index[-1] + pd.Timedelta(days=1), periods=future_days\n",
        "    )\n",
        "\n",
        "    forecast_df = pd.DataFrame({\"Date\": future_dates, \"Predicted_Discount\": forecast})\n",
        "    forecast_df.set_index(\"Date\", inplace=True)\n",
        "\n",
        "    return forecast_df\n",
        "\n",
        "#webhook contains its message payload and its head\n",
        "def send_to_slack(data):\n",
        "    \"\"\" \"\"\"\n",
        "    payload = {\"text\": data}\n",
        "    response = requests.post(\n",
        "        SLACK_WEBHOOK,\n",
        "        data=json.dumps(payload),\n",
        "        headers={\"Content-Type\": \"application/json\"},\n",
        "    )\n",
        "\n",
        "#generating recommendations\n",
        "def generate_strategy_recommendation(product_name, competitor_data, sentiment):\n",
        "    \"\"\"Generate strategic recommendations using an LLM.\"\"\"\n",
        "    date = datetime.now()\n",
        "    prompt = f\"\"\"\n",
        "    You are a highly skilled business strategist specializing in e-commerce. Based on the following details, suggest actionable strategies to optimize pricing, promotions, and customer satisfaction for the selected product:\n",
        "\n",
        "1. *Product Name*: {product_name}\n",
        "\n",
        "2. *Competitor Data* (including current prices, discounts, and predicted discounts):\n",
        "{competitor_data}\n",
        "\n",
        "3. *Sentiment Analysis*:\n",
        "{sentiment}\n",
        "\n",
        "\n",
        "5. *Today's Date*: {str(date)}\n",
        "\n",
        "### Task:\n",
        "- Analyze the competitor data and identify key pricing trends.\n",
        "- Leverage sentiment analysis insights to highlight areas where customer satisfaction can be improved.\n",
        "- Use the discount predictions to suggest how pricing strategies can be optimized over the next 5 days.\n",
        "- Recommend promotional campaigns or marketing strategies that align with customer sentiments and competitive trends.\n",
        "- Ensure the strategies are actionable, realistic, and geared toward increasing customer satisfaction, driving sales, and outperforming competitors.\n",
        "\n",
        "Provide your recommendations in a structured format:\n",
        "1. *Pricing Strategy*\n",
        "2. *Promotional Campaign Ideas*\n",
        "3. *Customer Satisfaction Recommendations*\n",
        "    \"\"\"\n",
        "\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "    data = {\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "        \"model\": \"llama3-8b-8192\",\n",
        "        \"temperature\": 0,\n",
        "    }\n",
        "\n",
        "    headers = {\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {API_KEY}\"}\n",
        "\n",
        "    res = requests.post(\n",
        "        \"https://api.groq.com/openai/v1/chat/completions\",\n",
        "        data=json.dumps(data),\n",
        "        headers=headers,\n",
        "    )\n",
        "    res = res.json()\n",
        "    response = res[\"choices\"][0][\"message\"][\"content\"]\n",
        "    return response\n",
        "\n",
        "\n",
        "####--------------------------------------------------##########\n",
        "#Streamlit app title\n",
        "st.set_page_config(page_title=\"E-Commerce Competitor Strategy Dashboard\", layout=\"wide\")\n",
        "\n",
        "\n",
        "st.title(\"E-Commerce Competitor Strategy Dashboard\")\n",
        "st.sidebar.header(\"Select a Product\")\n",
        "\n",
        "products = [\n",
        "    \"boAt Rockerz 480 w/RGB LEDs, 6 Light Modes, 40mm Drivers, Beast Mode, 60hrs Playback, ENx Tech, BT v5.3, Adaptive Fit & Easy Access Controls, Bluetooth Headphones(Black Sabre)\",\n",
        "    \"HP Victus, 13th Gen Intel Core i5-13420H, 6GB NVIDIA RTX 4050, 16GB DDR4, 512GB SSD (Win11, Office 21, Silver, 2.29kg) 144Hz, 9MS, IPS, 15.6-inch(39.6cm) FHD Gaming Laptop, Enhanced Cooling, fa1319TX\",\n",
        "    \"HAVAI Thunder 85 Desert Cooler - 75 Litres, 16 Inch Blade, Black\",\n",
        "    \"Samsung Galaxy M05 (Mint Green, 4GB RAM, 64 GB Storage) | 50MP Dual Camera | Bigger 6.7 HD+ Display | 5000mAh Battery | 25W Fast Charging | 2 Gen OS Upgrade & 4 Year Security Update | Without Charger\",\n",
        "    \"iQOO Z9x 5G (Tornado Green, 6GB RAM, 128GB Storage) | Snapdragon 6 Gen 1 with 560k+ AnTuTu Score | 6000mAh Battery with 7.99mm Slim Design | 44W FlashCharge\"\n",
        "]\n",
        "selected_product = st.sidebar.selectbox(\"Choose a product to analyze:\", products)\n",
        "\n",
        "#calling functions part of Driver Code\n",
        "competitor_data = load_competitor_data()\n",
        "reviews_data = load_reviews_data()\n",
        "\n",
        "product_data = competitor_data[competitor_data[\"Title\"] == selected_product]\n",
        "product_reviews = reviews_data[reviews_data[\"Title\"] == selected_product]\n",
        "\n",
        "st.header(f\"Competitor Analysis for {selected_product}\")\n",
        "st.subheader(\"Competitor Data\")\n",
        "st.table(product_data.tail(5))\n",
        "\n",
        "if not product_reviews.empty:\n",
        "    product_reviews[\"Reviews\"] = product_reviews[\"Reviews\"].apply(\n",
        "        lambda x: truncate_text(x, 512)\n",
        "    )\n",
        "    reviews = product_reviews[\"Reviews\"].tolist()\n",
        "    sentiments = analyze_sentiment(reviews)\n",
        "\n",
        "    st.subheader(\"Customer Sentiment Analysis\")\n",
        "    sentiment_df = pd.DataFrame(sentiments)\n",
        "    fig = px.bar(sentiment_df, x=\"label\", title=\"Sentiment Analysis Results\")\n",
        "    st.plotly_chart(fig)\n",
        "else:\n",
        "    st.write(\"No reviews available for this product.\")\n",
        "\n",
        "\n",
        "# Preprocessing\n",
        "product_data[\"Date\"] = pd.to_datetime(product_data[\"Date\"], errors=\"coerce\")\n",
        "product_data = product_data.dropna(subset=[\"Date\"])\n",
        "product_data.set_index(\"Date\", inplace=True)\n",
        "product_data = product_data.sort_index()\n",
        "\n",
        "product_data[\"Discount\"] = pd.to_numeric(product_data[\"Discount\"], errors=\"coerce\")\n",
        "product_data = product_data.dropna(subset=[\"Discount\"])\n",
        "\n",
        "# Forecasting Model\n",
        "product_data_with_predictions = forecast_discounts_arima(product_data)\n",
        "\n",
        "\n",
        "st.subheader(\"Competitor Current and Predicted Discounts\")\n",
        "st.table(product_data_with_predictions.tail(10))\n",
        "\n",
        "recommendations = generate_strategy_recommendation(\n",
        "    selected_product,\n",
        "    product_data_with_predictions,\n",
        "    sentiments if not product_reviews.empty else \"No reviews available\",\n",
        ")\n",
        "st.subheader(\"Strategic Recommendations\")\n",
        "st.write(recommendations)\n",
        "send_to_slack(recommendations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mUB3ndO5J9Gy",
        "outputId": "d815f2d8-0460-4b23-df1c-3e83b15bf4c3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-01-28 13:53:43.515 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-28 13:53:43.520 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-28 13:53:43.523 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-28 13:53:43.534 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-28 13:53:43.538 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-28 13:53:43.539 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-28 13:53:43.543 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-28 13:53:43.544 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-28 13:53:43.552 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-28 13:53:43.566 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-28 13:53:43.571 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-28 13:53:43.600 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-28 13:53:43.606 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-28 13:53:43.609 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-28 13:53:43.611 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-28 13:53:43.620 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-28 13:53:43.629 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-28 13:53:43.631 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "<ipython-input-21-01540dc0c786>:192: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  Date                                              Title  \\\n",
            "0  2025-01-28 13:37:56  boAt Rockerz 480 w/RGB LEDs, 6 Light Modes, 40...   \n",
            "1  2025-01-28 13:38:00  HP Victus, 13th Gen Intel Core i5-13420H, 6GB ...   \n",
            "2  2025-01-28 13:38:04  HAVAI Thunder 85 Desert Cooler - 75 Litres, 16...   \n",
            "3  2025-01-28 13:38:07  Samsung Galaxy M05 (Mint Green, 4GB RAM, 64 GB...   \n",
            "4  2025-01-28 13:38:09  iQOO Z9x 5G (Tornado Green, 6GB RAM, 128GB Sto...   \n",
            "\n",
            "     Price  MRP Price Availability  \n",
            "0   1,799.     2158.8     In stock  \n",
            "1  80,990.    97188.0     In stock  \n",
            "2  10,985.    13182.0     In stock  \n",
            "3   6,499.     7798.8     In stock  \n",
            "4  13,499.    16198.8     In stock  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "2025-01-28 13:53:44.768 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-28 13:53:44.771 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-28 13:53:44.825 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-28 13:53:44.828 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-28 13:53:44.830 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-28 13:53:44.833 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "<ipython-input-21-01540dc0c786>:207: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'Discount'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Discount'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-01540dc0c786>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0mproduct_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproduct_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m \u001b[0mproduct_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Discount\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproduct_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Discount\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"coerce\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0mproduct_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproduct_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Discount\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Discount'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import requests\n",
        "import streamlit as st\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from transformers import pipeline\n",
        "\n",
        "# Use environment variables for sensitive data\n",
        "API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
        "SLACK_WEBHOOK = os.getenv(\"SLACK_WEBHOOK_URL\")\n",
        "\n",
        "# Utility function for truncating text\n",
        "def truncate_text(text, max_length=512):\n",
        "    return text[:max_length]\n",
        "\n",
        "@st.cache_data\n",
        "def load_price_data():\n",
        "    \"\"\"Load price data from a CSV file.\"\"\"\n",
        "    try:\n",
        "        data = pd.read_csv(\"/mnt/data/amazon_price.csv\")\n",
        "        data[\"Price\"] = data[\"Price\"].str.replace(\",\", \"\").astype(float)\n",
        "        data[\"MRP Price\"] = data[\"MRP Price\"].str.replace(\",\", \"\").astype(float)\n",
        "        data[\"Discount (%)\"] = data[\"Discount (%)\"].astype(float)\n",
        "        data[\"Date\"] = pd.to_datetime(data[\"Date\"], errors=\"coerce\")\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error loading price data: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "@st.cache_data\n",
        "def load_reviews_data():\n",
        "    \"\"\"Load reviews data from a CSV file.\"\"\"\n",
        "    try:\n",
        "        return pd.read_csv(\"/mnt/data/amazon_reviews.csv\")\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error loading reviews data: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def analyze_sentiment(reviews):\n",
        "    \"\"\"Analyze customer sentiment for reviews.\"\"\"\n",
        "    try:\n",
        "        sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
        "        return sentiment_pipeline(reviews)\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error analyzing sentiment: {e}\")\n",
        "        return []\n",
        "\n",
        "@st.cache_data\n",
        "def train_predictive_model(data):\n",
        "    \"\"\"Train a predictive model for competitor pricing strategy.\"\"\"\n",
        "    try:\n",
        "        X = data[[\"Price\", \"Discount (%)\"]]\n",
        "        y = data[\"MRP Price\"]\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42, train_size=0.8\n",
        "        )\n",
        "        model = RandomForestRegressor(random_state=42)\n",
        "        model.fit(X_train, y_train)\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error training model: {e}\")\n",
        "        return None\n",
        "\n",
        "@st.cache_data\n",
        "def forecast_discounts_arima(data, future_days=5):\n",
        "    \"\"\"Forecast future discounts using ARIMA.\"\"\"\n",
        "    try:\n",
        "        data = data.sort_index()\n",
        "        data = data.dropna(subset=[\"Discount (%)\"])\n",
        "        discount_series = data[\"Discount (%)\"]\n",
        "\n",
        "        model = ARIMA(discount_series, order=(5, 1, 0))\n",
        "        model_fit = model.fit()\n",
        "\n",
        "        forecast = model_fit.forecast(steps=future_days)\n",
        "        future_dates = pd.date_range(\n",
        "            start=discount_series.index[-1] + pd.Timedelta(days=1), periods=future_days\n",
        "        )\n",
        "\n",
        "        forecast_df = pd.DataFrame({\"Date\": future_dates, \"Predicted_Discount (%)\": forecast})\n",
        "        forecast_df.set_index(\"Date\", inplace=True)\n",
        "\n",
        "        return forecast_df\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error forecasting discounts: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def send_to_slack(data):\n",
        "    \"\"\"Send recommendations to Slack.\"\"\"\n",
        "    try:\n",
        "        payload = {\"text\": data}\n",
        "        requests.post(\n",
        "            SLACK_WEBHOOK,\n",
        "            data=json.dumps(payload),\n",
        "            headers={\"Content-Type\": \"application/json\"},\n",
        "        )\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error sending data to Slack: {e}\")\n",
        "\n",
        "def generate_strategy_recommendation(product_name, competitor_data, sentiment):\n",
        "    \"\"\"Generate strategic recommendations using an LLM.\"\"\"\n",
        "    try:\n",
        "        date = datetime.now()\n",
        "        prompt = f\"\"\"\n",
        "        You are a highly skilled business strategist specializing in e-commerce. Based on the following details, suggest actionable strategies to optimize pricing, promotions, and customer satisfaction for the selected product:\n",
        "\n",
        "        1. *Product Name*: {product_name}\n",
        "\n",
        "        2. *Competitor Data* (including current prices, discounts, and predicted discounts):\n",
        "        {competitor_data}\n",
        "\n",
        "        3. *Sentiment Analysis*:\n",
        "        {sentiment}\n",
        "\n",
        "        5. *Today's Date*: {str(date)}\n",
        "\n",
        "        ### Task:\n",
        "        - Analyze the competitor data and identify key pricing trends.\n",
        "        - Leverage sentiment analysis insights to highlight areas where customer satisfaction can be improved.\n",
        "        - Use the discount predictions to suggest how pricing strategies can be optimized over the next 5 days.\n",
        "        - Recommend promotional campaigns or marketing strategies that align with customer sentiments and competitive trends.\n",
        "        \"\"\"\n",
        "\n",
        "        data = {\n",
        "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "            \"model\": \"llama3-8b-8192\",\n",
        "            \"temperature\": 0,\n",
        "        }\n",
        "        headers = {\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {API_KEY}\"}\n",
        "        res = requests.post(\n",
        "            \"https://api.groq.com/openai/v1/chat/completions\",\n",
        "            data=json.dumps(data),\n",
        "            headers=headers,\n",
        "        )\n",
        "        res = res.json()\n",
        "        return res[\"choices\"][0][\"message\"][\"content\"]\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error generating strategy: {e}\")\n",
        "        return \"Error generating strategy.\"\n",
        "\n",
        "#### Streamlit Dashboard ####\n",
        "st.set_page_config(page_title=\"E-Commerce Competitor Strategy Dashboard\", layout=\"wide\")\n",
        "st.title(\"E-Commerce Competitor Strategy Dashboard\")\n",
        "st.sidebar.header(\"Select a Product\")\n",
        "\n",
        "price_data = load_price_data()\n",
        "reviews_data = load_reviews_data()\n",
        "\n",
        "if price_data.empty or reviews_data.empty:\n",
        "    st.error(\"Ensure the necessary data files are available.\")\n",
        "else:\n",
        "    products = price_data[\"Title\"].unique()\n",
        "    selected_product = st.sidebar.selectbox(\"Choose a product to analyze:\", products)\n",
        "\n",
        "    product_data = price_data[price_data[\"Title\"] == selected_product]\n",
        "    product_reviews = reviews_data[reviews_data[\"Title\"] == selected_product]\n",
        "\n",
        "    st.header(f\"Competitor Analysis for {selected_product}\")\n",
        "    st.subheader(\"Competitor Data\")\n",
        "    st.table(product_data.tail(5))\n",
        "\n",
        "    if not product_reviews.empty:\n",
        "        reviews = product_reviews[\"Review\"].apply(lambda x: truncate_text(x, 512)).tolist()\n",
        "        sentiments = analyze_sentiment(reviews)\n",
        "        st.subheader(\"Customer Sentiment Analysis\")\n",
        "        sentiment_df = pd.DataFrame(sentiments)\n",
        "        fig = px.bar(sentiment_df, x=\"label\", title=\"Sentiment Analysis Results\")\n",
        "        st.plotly_chart(fig)\n",
        "    else:\n",
        "        st.write(\"No reviews available for this product.\")\n",
        "\n",
        "    # Preprocessing for forecasting\n",
        "    product_data.set_index(\"Date\", inplace=True)\n",
        "    product_data_with_predictions = forecast_discounts_arima(product_data)\n",
        "\n",
        "    st.subheader(\"Competitor Current and Predicted Discounts\")\n",
        "    st.table(product_data_with_predictions.tail(10))\n",
        "\n",
        "    recommendations = generate_strategy_recommendation(\n",
        "        selected_product,\n",
        "        product_data_with_predictions,\n",
        "        sentiments if not product_reviews.empty else \"No reviews available\",\n",
        "    )\n",
        "\n",
        "    st.subheader(\"Strategic Recommendations\")\n",
        "    st.write(recommendations)\n",
        "    send_to_slack(recommendations)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jklOvSCQf4H",
        "outputId": "f5d7c5fd-4e02-4d7e-e8a1-3cb06ee1c5fe"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-01-28 14:13:03.094 No runtime found, using MemoryCacheStorageManager\n",
            "2025-01-28 14:13:03.110 No runtime found, using MemoryCacheStorageManager\n",
            "2025-01-28 14:13:03.119 No runtime found, using MemoryCacheStorageManager\n",
            "2025-01-28 14:13:03.123 No runtime found, using MemoryCacheStorageManager\n",
            "2025-01-28 14:13:03.132 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-28 14:13:03.134 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-28 14:13:03.135 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-28 14:13:03.139 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-28 14:13:03.142 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-28 14:13:03.150 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-28 14:13:03.152 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    }
  ]
}